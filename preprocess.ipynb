{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = 'data/train_v2/'\n",
    "\n",
    "csv_path = 'data_p/s.csv'\n",
    "\n",
    "image_path = 'data_p/s/image/'\n",
    "mask_path = 'data_p/s/mask/'\n",
    "\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "if not os.path.exists(mask_path):\n",
    "    os.makedirs(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_dataset(path):\n",
    "    return tf.data.experimental.make_csv_dataset(\n",
    "        path,\n",
    "        batch_size=1, # required\n",
    "        column_names=['ImageId', 'EncodedPixels'],\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(encoded_pixels, image_height=768, image_width=768):\n",
    "    mask = tf.zeros(image_height * image_width, dtype=tf.float32)\n",
    "\n",
    "    # Convert string to integer tensor\n",
    "    pairs = tf.strings.to_number(tf.strings.split(encoded_pixels), out_type=tf.int32)\n",
    "\n",
    "    # Iterate over pairs and update mask\n",
    "    for i in range(0, len(pairs), 2):\n",
    "        start = pairs[i] - 1\n",
    "        run_length = pairs[i + 1]\n",
    "\n",
    "        indices = tf.range(start, start + run_length)\n",
    "        updates = tf.ones(run_length, dtype=tf.float32)\n",
    "        mask = tf.tensor_scatter_nd_update(mask, indices=tf.expand_dims(indices, axis=1), updates=updates)\n",
    "\n",
    "    return  tf.transpose(tf.reshape(mask, (image_height, image_width)))\n",
    "\n",
    "def process_image(file):\n",
    "    img = tf.io.read_file(train_image_path + file)\n",
    "    tf.io.write_file(image_path + file, img)\n",
    "    return img\n",
    "\n",
    "def process_mask(rle, file):\n",
    "    mask = rle_to_mask(rle)\n",
    "    encoded_mask = tf.io.serialize_tensor(mask)\n",
    "    tf.io.write_file(mask_path + file, encoded_mask)\n",
    "    return mask\n",
    "\n",
    "def process_batch(csv_item):\n",
    "    X = process_image(csv_item['ImageId'])\n",
    "    y = process_mask(csv_item['EncodedPixels'], csv_item['ImageId'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv_dataset(csv_path)\n",
    "\n",
    "# use map in hacky way to process in parallel\n",
    "r = csv.unbatch().map(process_batch)\n",
    "# apply the function to each batch\n",
    "for batch in r.batch(32):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
