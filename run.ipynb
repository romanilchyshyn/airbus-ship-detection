{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('efficientnetb2', classes=1, activation='sigmoid')\n",
    "model.load_weights('models/data_l_100e_b2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: reuse from train\n",
    "\n",
    "data_p_dir = 'data_p/s/'\n",
    "image_dir = data_p_dir + 'image/'\n",
    "label_dir = data_p_dir + 'label/'\n",
    "\n",
    "image_file_paths = tf.data.Dataset.list_files(image_dir + '*.jpg', shuffle=False)\n",
    "label_file_paths = tf.data.Dataset.list_files(label_dir + '*.jpg', shuffle=False)\n",
    "\n",
    "def process_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    return img\n",
    "\n",
    "def process_label(path):\n",
    "    mask = tf.io.read_file(path)\n",
    "    img = tf.io.parse_tensor(mask, out_type=tf.float32)\n",
    "    return img\n",
    "\n",
    "def process_batch(image, label):\n",
    "    X = process_img(image)\n",
    "    y = process_label(label)\n",
    "    return X, y\n",
    "\n",
    "def plot_ds_element_overlay(background, overlay):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(background)\n",
    "    ax.imshow(overlay, alpha=0.3)\n",
    "\n",
    "def plot_ds_element(background, overlay):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].imshow(background)\n",
    "    axs[1].imshow(overlay)\n",
    "    plt.show()\n",
    "\n",
    "d = tf.data.Dataset.zip((image_file_paths, label_file_paths)).map(process_batch)\n",
    "\n",
    "SKIP = 0\n",
    "item = d.batch(1).skip(SKIP).take(20)\n",
    "\n",
    "for i, l in item:\n",
    "    plot_ds_element(i[0], l[0])\n",
    "    p = model.predict(i)\n",
    "    plot_ds_element(p[0], p[0])\n",
    "\n",
    "# for i, l in item:\n",
    "#     print(len(i))\n",
    "#     p = model.predict(i)\n",
    "#     plot_ds_element(p[0], p[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
