{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    }
   ],
   "source": [
    "%set_env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models as sm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p_dir = 'data_p/s/'\n",
    "image_dir = data_p_dir + 'image/'\n",
    "label_dir = data_p_dir + 'label/'\n",
    "\n",
    "dataset = dataset.train_dataset(image_dir, label_dir)\n",
    "dataset = dataset.shuffle(buffer_size=10000, seed=SEED)\n",
    "\n",
    "split_ratio = 0.8\n",
    "num_samples = dataset.cardinality().numpy()\n",
    "num_train = int(split_ratio * num_samples)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_ds = dataset.take(num_train)\n",
    "val_ds = dataset.skip(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('efficientnetb2', classes=1, activation='sigmoid')\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "model.compile('adam', sm.losses.DiceLoss(), metrics)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_callbacks():\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    checkpoint_path = \"model_checkpoint.h5\"\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return [tensorboard_callback, checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 15:47:42.739479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 0.9790 - iou_score: 0.0135 - f1-score: 0.0266\n",
      "Epoch 1: val_loss improved from inf to 0.99395, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 24s 3s/step - loss: 0.9790 - iou_score: 0.0135 - f1-score: 0.0266 - val_loss: 0.9940 - val_iou_score: 0.0030 - val_f1-score: 0.0060\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9652 - iou_score: 0.0369 - f1-score: 0.0704\n",
      "Epoch 2: val_loss improved from 0.99395 to 0.97568, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 10s 2s/step - loss: 0.9652 - iou_score: 0.0369 - f1-score: 0.0704 - val_loss: 0.9757 - val_iou_score: 0.0123 - val_f1-score: 0.0243\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9656 - iou_score: 0.0605 - f1-score: 0.1133\n",
      "Epoch 3: val_loss did not improve from 0.97568\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9656 - iou_score: 0.0605 - f1-score: 0.1133 - val_loss: 0.9813 - val_iou_score: 0.0095 - val_f1-score: 0.0187\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9538 - iou_score: 0.1107 - f1-score: 0.1966\n",
      "Epoch 4: val_loss improved from 0.97568 to 0.97410, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9538 - iou_score: 0.1107 - f1-score: 0.1966 - val_loss: 0.9741 - val_iou_score: 0.0131 - val_f1-score: 0.0259\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9543 - iou_score: 0.1364 - f1-score: 0.2287\n",
      "Epoch 5: val_loss did not improve from 0.97410\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9543 - iou_score: 0.1364 - f1-score: 0.2287 - val_loss: 0.9835 - val_iou_score: 0.0083 - val_f1-score: 0.0165\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9336 - iou_score: 0.1597 - f1-score: 0.2738\n",
      "Epoch 6: val_loss improved from 0.97410 to 0.96966, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9336 - iou_score: 0.1597 - f1-score: 0.2738 - val_loss: 0.9697 - val_iou_score: 0.0154 - val_f1-score: 0.0303\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9359 - iou_score: 0.1419 - f1-score: 0.2409\n",
      "Epoch 7: val_loss did not improve from 0.96966\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9359 - iou_score: 0.1419 - f1-score: 0.2409 - val_loss: 0.9925 - val_iou_score: 0.0038 - val_f1-score: 0.0075\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9278 - iou_score: 0.1450 - f1-score: 0.2506\n",
      "Epoch 8: val_loss did not improve from 0.96966\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9278 - iou_score: 0.1450 - f1-score: 0.2506 - val_loss: 0.9922 - val_iou_score: 0.0039 - val_f1-score: 0.0078\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9175 - iou_score: 0.1516 - f1-score: 0.2562\n",
      "Epoch 9: val_loss did not improve from 0.96966\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.9175 - iou_score: 0.1516 - f1-score: 0.2562 - val_loss: 0.9835 - val_iou_score: 0.0083 - val_f1-score: 0.0165\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8676 - iou_score: 0.2321 - f1-score: 0.3745\n",
      "Epoch 10: val_loss did not improve from 0.96966\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.8676 - iou_score: 0.2321 - f1-score: 0.3745 - val_loss: 0.9982 - val_iou_score: 8.8925e-04 - val_f1-score: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2948f31d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=make_callbacks())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
