{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "# train_csv_file_path = data_path + 'train_ship_segmentations_v2.csv'\n",
    "train_csv_file_path = data_path + 'train_ship_segmentations_v2_clean.csv'\n",
    "# train_csv_file_path = data_path + 'demo.csv'\n",
    "# train_csv_file_path = data_path + 'demo_clean.csv'\n",
    "train_image_path = data_path + 'train_v2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 12:31:10.873361: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-02-09 12:31:10.873379: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-02-09 12:31:10.873383: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-02-09 12:31:10.873413: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-09 12:31:10.873427: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def load_csv(path):\n",
    "    return tf.data.experimental.make_csv_dataset(\n",
    "        path,\n",
    "        batch_size=1, # required\n",
    "        column_names=['ImageId', 'EncodedPixels'],\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "train_csv = load_csv(train_csv_file_path)\n",
    "\n",
    "# for batch in train_csv.take(1):\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 768\n",
    "IMG_WIDTH = 768\n",
    "\n",
    "@tf.function\n",
    "def process_img(file):\n",
    "    img = tf.io.read_file(train_image_path + file)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "@tf.function\n",
    "def decode_label_mask(encoded_pixels, image_height, image_width):\n",
    "    mask = tf.zeros(image_height * image_width, dtype=tf.float32)\n",
    "\n",
    "    # Convert string to integer tensor\n",
    "    pairs = tf.strings.to_number(tf.strings.split(encoded_pixels), out_type=tf.int32)\n",
    "\n",
    "    # Iterate over pairs and update mask\n",
    "    for i in range(0, len(pairs), 2):\n",
    "        start = pairs[i] - 1\n",
    "        run_length = pairs[i + 1]\n",
    "\n",
    "        indices = tf.range(start, start + run_length)\n",
    "        updates = tf.ones(run_length, dtype=tf.float32)\n",
    "        mask = tf.tensor_scatter_nd_update(mask, indices=tf.expand_dims(indices, axis=1), updates=updates)\n",
    "\n",
    "    return  tf.transpose(tf.reshape(mask, (image_height, image_width)))\n",
    "\n",
    "@tf.function\n",
    "def process_label(label):\n",
    "    return decode_label_mask(label, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "@tf.function\n",
    "def process_batch(csv_item):\n",
    "    X = process_img(csv_item['ImageId'])\n",
    "    y = process_label(csv_item['EncodedPixels'])\n",
    "    return X, y\n",
    "\n",
    "def plot_ds_element(background, overlay):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(background)\n",
    "    ax.imshow(overlay, alpha=0.3)\n",
    "\n",
    "train_ds = train_csv.unbatch().map(process_batch)\n",
    "\n",
    "# a = train_ds.batch(32).take(1000).reduce(0, lambda x, _: x + 1).numpy()\n",
    "# print(a)\n",
    "\n",
    "# for item, label in train_ds.skip(2).take(1):\n",
    "#     plot_ds_element(item, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "\n",
    "    norm_inputs = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs) # mo to preprocessing\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(norm_inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Bottom\n",
    "    conv4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
    "    up5 = tf.keras.layers.concatenate([up5, conv3], axis=-1)\n",
    "    conv5 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(up5)\n",
    "    conv5 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    up6 = tf.keras.layers.concatenate([up6, conv2], axis=-1)\n",
    "    conv6 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = tf.keras.layers.concatenate([up7, conv1], axis=-1)\n",
    "    conv7 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model = unet()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coefficient])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 12:31:17.234479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 8s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 12:31:24.513200: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11074633200316695256\n",
      "2024-02-09 12:31:24.513235: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12400806594822815843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0021\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0021\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0021\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9975 - dice_coefficient: 0.0022\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9975 - dice_coefficient: 0.0022\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9974 - dice_coefficient: 0.0023\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9973 - dice_coefficient: 0.0024\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0021\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9975 - dice_coefficient: 0.0022\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0021\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0021\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0021\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9976 - dice_coefficient: 0.0022\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9974 - dice_coefficient: 0.0023\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9973 - dice_coefficient: 0.0024\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9973 - dice_coefficient: 0.0024\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9971 - dice_coefficient: 0.0026\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9972 - dice_coefficient: 0.0024\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9972 - dice_coefficient: 0.0024\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9972 - dice_coefficient: 0.0024\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9972 - dice_coefficient: 0.0025\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9971 - dice_coefficient: 0.0025\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9970 - dice_coefficient: 0.0026\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9968 - dice_coefficient: 0.0029\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9988 - dice_coefficient: 0.0015\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9974 - dice_coefficient: 0.0025\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9964 - dice_coefficient: 0.0041\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.9977 - dice_coefficient: 0.0021\n",
      "Epoch 237/1000\n",
      "1/3 [=========>....................] - ETA: 5s - loss: 0.9959 - dice_coefficient: 0.0041"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/engine/training.py:1813\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1812\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1813\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1815\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:394\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:360\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.take(10).batch(4).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "model.fit(train_ds, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
