{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "train_csv_file_path = data_path + 'train_ship_segmentations_v2.csv'\n",
    "# train_csv_file_path = data_path + 'demo.csv'\n",
    "train_image_path = data_path + 'train_v2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    return tf.data.experimental.make_csv_dataset(\n",
    "        path,\n",
    "        batch_size=1, # required\n",
    "        column_names=['ImageId', 'EncodedPixels'],\n",
    "        num_epochs=1,\n",
    "    )\n",
    "\n",
    "train_csv = load_csv(train_csv_file_path)\n",
    "\n",
    "# for batch in train_csv.take(1):\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 20:23:39.118245: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at scatter_nd_op.cc:218 : INVALID_ARGUMENT: indices[51] = [589824] does not index into shape [589824]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ReduceDataset_Targuments_0_Tstate_1_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[51] = [589824] does not index into shape [589824]\n\t [[{{function_node while_body_99129}}{{node while/TensorScatterUpdate}}]] [Op:ReduceDataset] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m train_csv\u001b[38;5;241m.\u001b[39munbatch()\u001b[38;5;241m.\u001b[39mmap(process_batch)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# train_ds.filter(lambda x, y: x.shape > 0)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL=\u001b[39m\u001b[38;5;124m'\u001b[39m, L)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item, label \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2793\u001b[0m, in \u001b[0;36mDatasetV2.reduce\u001b[0;34m(self, initial_state, reduce_func, name)\u001b[0m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n\u001b[1;32m   2790\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m _validate_and_encode(name)\n\u001b[1;32m   2791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m structure\u001b[38;5;241m.\u001b[39mfrom_compatible_tensor_list(\n\u001b[1;32m   2792\u001b[0m     state_structure,\n\u001b[0;32m-> 2793\u001b[0m     \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2799\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_tensor_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_structure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:6179\u001b[0m, in \u001b[0;36mreduce_dataset\u001b[0;34m(input_dataset, initial_state, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, metadata, name)\u001b[0m\n\u001b[1;32m   6177\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   6178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 6179\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   6181\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/winstars/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ReduceDataset_Targuments_0_Tstate_1_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[51] = [589824] does not index into shape [589824]\n\t [[{{function_node while_body_99129}}{{node while/TensorScatterUpdate}}]] [Op:ReduceDataset] name: "
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = 768\n",
    "IMG_WIDTH = 768\n",
    "\n",
    "def process_img(file):\n",
    "    img = tf.io.read_file(train_image_path + file)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    return img\n",
    "\n",
    "def decode_label_mask(encoded_pixels, image_height, image_width):\n",
    "    mask = tf.zeros(image_height * image_width, dtype=tf.uint8)\n",
    "\n",
    "    # Convert string to integer tensor\n",
    "    pairs = tf.strings.to_number(tf.strings.split(encoded_pixels), out_type=tf.int32)\n",
    "\n",
    "    # Iterate over pairs and update mask\n",
    "    for i in range(0, len(pairs), 2):\n",
    "        start = pairs[i] - 1\n",
    "        run_length = pairs[i + 1]\n",
    "\n",
    "        indices = tf.range(start, start + run_length)\n",
    "        updates = tf.ones(run_length, dtype=tf.uint8)\n",
    "        mask = tf.tensor_scatter_nd_update(mask, indices=tf.expand_dims(indices, axis=1), updates=updates)\n",
    "\n",
    "    return  tf.reshape(mask, (image_height, image_width))\n",
    "\n",
    "def process_label(label):\n",
    "    return decode_label_mask(label, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "def process_batch(csv_item):\n",
    "    X = process_img(csv_item['ImageId'])\n",
    "    y = process_label(csv_item['EncodedPixels'])\n",
    "    return X, y\n",
    "\n",
    "train_ds = train_csv.unbatch().map(process_batch)\n",
    "# train_ds.filter(lambda x, y: x.shape > 0)\n",
    "\n",
    "L = train_ds.reduce(0, lambda x, _: x + 1)\n",
    "print('L=', L)\n",
    "\n",
    "for item, label in train_ds.take(1):\n",
    "    background = item\n",
    "    overlay = label\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(background)\n",
    "    \n",
    "    ax.imshow(overlay, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
